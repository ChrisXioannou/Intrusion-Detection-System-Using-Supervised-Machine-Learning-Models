{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **BINARY CLASSIFICATION**"
      ],
      "metadata": {
        "id": "_OVEXfTJhsA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAIN**"
      ],
      "metadata": {
        "id": "HwElA1ppi0_f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3LI5F2XLWQ5"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount gdrive directory\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Global path variables\n",
        "BALANCED_TRAIN_DATASET_PATH =\n",
        "TEST_DATASET_PATH =\n",
        "BINARY_RESULTS_SAVE_PATH =\n",
        "BINARY_RESULTS_FILE_PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y4Q_fjiLoIY",
        "outputId": "836df38f-abc6-4a59-dced-f57b83c37e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training dataset\n",
        "train_df = pd.read_csv(BALANCED_TRAIN_DATASET_PATH)\n",
        "\n",
        "# Verify the class distribution in the training data\n",
        "print(f\"train_df shape: {train_df.shape}\")\n",
        "train_class_distribution = train_df['category'].value_counts()\n",
        "print(\"Train class distribution:\\n\", train_class_distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J9U99xBLnUY",
        "outputId": "8e3ee742-4cc2-4fb3-d0ba-363f56601d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df shape: (401860, 110)\n",
            "Train class distribution:\n",
            " category\n",
            "0    200000\n",
            "1    180000\n",
            "2     13860\n",
            "3      5000\n",
            "4      3000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert category column to binary classes\n",
        "train_df['category'] = train_df['category'].apply(lambda x: 0 if x == 0 else 1)\n",
        "\n",
        "# Verify the new class distribution\n",
        "binary_class_distribution = train_df['category'].value_counts()\n",
        "print(\"Binary Class Distribution:\\n\", binary_class_distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1kqeJ6YMMnB",
        "outputId": "6dfbf156-d126-426d-a63e-8b01085e328e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Class Distribution:\n",
            " category\n",
            "1    201860\n",
            "0    200000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting inputData (features) and outputData (labels)\n",
        "X = train_df.drop(columns=['category']).values  # Features\n",
        "y = train_df['category'].values  # Labels\n",
        "\n",
        "# Verify shapes and class distribution\n",
        "print(f\"Train Data Shape: X = {X.shape}, y = {y.shape}\")\n",
        "print(\"Class Distribution:\\n\", train_df['category'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SElVhcQ-MSaI",
        "outputId": "1f3200fc-ef8a-493c-808d-72b867c6de3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Shape: X = (401860, 109), y = (401860,)\n",
            "Class Distribution:\n",
            " category\n",
            "1    201860\n",
            "0    200000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Dictionary of all models used\n",
        "optimized_models = {\n",
        "    'random_forest': RandomForestClassifier(n_estimators=200, max_depth=None, random_state=42),\n",
        "    'knn': KNeighborsClassifier(n_neighbors=3, weights='uniform', metric='euclidean'),\n",
        "    'logistic_regression': LogisticRegression(C=1, solver='liblinear', max_iter=3000, random_state=42),\n",
        "    'xgboost': XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42),  # Replacing SVM\n",
        "    'naive_bayes': GaussianNB()\n",
        "}"
      ],
      "metadata": {
        "id": "UznK2iOuNDsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store trained models\n",
        "trained_models = {}\n",
        "\n",
        "# Train all models and store in dictionary\n",
        "for model_name, model in optimized_models.items():\n",
        "    print(f\"\\nTraining {model_name.replace('_', ' ').capitalize()}...\")\n",
        "    model.fit(X, y)  # Train model on entire dataset\n",
        "    trained_models[model_name] = model  # Store trained model\n",
        "\n",
        "print(\"All models trained and mapped successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM6nMW0GYzsa",
        "outputId": "96f33cb5-7451-4d82-fa40-8d7632a01080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Random forest...\n",
            "\n",
            "Training Knn...\n",
            "\n",
            "Training Logistic regression...\n",
            "\n",
            "Training Xgboost...\n",
            "\n",
            "Training Naive bayes...\n",
            "All models trained and mapped successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TESTING**"
      ],
      "metadata": {
        "id": "xvkAz2A0O3w5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test dataset\n",
        "test_df = pd.read_csv(TEST_DATASET_PATH)\n",
        "\n",
        "# Verify the class distribution in the test data\n",
        "test_class_distribution = test_df['category'].value_counts()\n",
        "print(\"Test class distribution:\\n\", test_class_distribution)\n",
        "\n",
        "# View the shape of the testing dataset\n",
        "print(f\"Test DataFrame shape: {test_df.shape}\")\n",
        "\n",
        "# Verify unique values in the 'category' column\n",
        "if 'category' in test_df.columns:\n",
        "    print(\"Unique values in 'category' column:\", test_df['category'].unique())\n",
        "else:\n",
        "    print(\"'category' column not found in test_df!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06QJWq2dOAEY",
        "outputId": "80b25d48-b9f1-4c5f-9e39-5ba483b13aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test class distribution:\n",
            " category\n",
            "0    47913\n",
            "1    23568\n",
            "3     3058\n",
            "2     2682\n",
            "4       70\n",
            "Name: count, dtype: int64\n",
            "Test DataFrame shape: (77291, 103)\n",
            "Unique values in 'category' column: [0 2 1 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert category column to binary classes\n",
        "test_df['category'] = test_df['category'].apply(lambda x: 0 if x == 0 else 1)\n",
        "\n",
        "# Verify the new class distribution\n",
        "binary_class_distribution = test_df['category'].value_counts()\n",
        "print(\"Binary Class Distribution:\\n\", binary_class_distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17Ps6BKMPXhK",
        "outputId": "8ee3edae-ec2d-4407-c58c-333deff4b2be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Class Distribution:\n",
            " category\n",
            "0    47913\n",
            "1    29378\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find differences in columns between train and test datasets\n",
        "train_columns = set(train_df.columns)\n",
        "test_columns = set(test_df.columns)\n",
        "\n",
        "# Columns in train but not in test\n",
        "only_in_train = train_columns - test_columns\n",
        "# Columns in test but not in train\n",
        "only_in_test = test_columns - train_columns\n",
        "\n",
        "# Print results\n",
        "if only_in_train:\n",
        "    print(f\"Columns in TRAIN but NOT in TEST: {only_in_train}\")\n",
        "else:\n",
        "    print(\"No extra columns found in TRAIN.\")\n",
        "\n",
        "if only_in_test:\n",
        "    print(f\"Columns in TEST but NOT in TRAIN: {only_in_test}\")\n",
        "else:\n",
        "    print(\"No extra columns found in TEST.\")\n",
        "\n",
        "# Print shapes before reindexing\n",
        "print(\"\\nBefore reindexing:\")\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "print(f\"Test shape: {test_df.shape}\")\n",
        "\n",
        "# Reindex test dataset to match train dataset columns\n",
        "test_df = test_df.reindex(columns=train_df.columns, fill_value=0)\n",
        "\n",
        "# Print shapes after reindexing\n",
        "print(\"\\nAfter reindexing:\")\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "print(f\"Test shape: {test_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is-5Alm15ux9",
        "outputId": "c74e250c-30da-4220-d814-7ed4eb5c8f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in TRAIN but NOT in TEST: {'srv_serror_rate', 'service_http_8001', 'serror_rate', 'service_red_i', 'service_urh_i', 'service_aol', 'service_http_2784', 'service_harvest'}\n",
            "Columns in TEST but NOT in TRAIN: {'service_icmp'}\n",
            "\n",
            "Before reindexing:\n",
            "Train shape: (401860, 110)\n",
            "Test shape: (77291, 103)\n",
            "\n",
            "After reindexing:\n",
            "Train shape: (401860, 110)\n",
            "Test shape: (77291, 110)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features (X_test) and labels (y_test)\n",
        "if 'category' in test_df.columns:\n",
        "    y_test_binary = test_df['category'].values  # Extract labels\n",
        "    X_test_binary = test_df.drop(columns=['category']).values  # Drop category to get features\n",
        "else:\n",
        "    raise ValueError(\"'category' column not found in test dataset!\")\n",
        "\n",
        "print(f\"Test dataset split successfully.\")\n",
        "print(f\"X_test shape: {X_test_binary.shape}\")\n",
        "print(f\"y_test shape: {y_test_binary.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl5TPbVA6H0s",
        "outputId": "b330f423-480f-462d-974c-e6c0f11224e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset split successfully.\n",
            "X_test shape: (77291, 109)\n",
            "y_test shape: (77291,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(BINARY_RESULTS_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Setup completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKEjDPC35KTe",
        "outputId": "243ea79d-3190-4aff-fa6e-0d4a1a58b4f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Setup completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize counters for total class counts\n",
        "total_attacks = np.sum(y_test_binary == 1)   # Total attack samples\n",
        "total_normals = np.sum(y_test_binary == 0)   # Total normal samples\n",
        "\n",
        "# File to save evaluation results\n",
        "results_file = os.path.join(results_dir, \"evaluation_results_binary.txt\")"
      ],
      "metadata": {
        "id": "HH7hjWsE5hHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variable for binary thesis evaluation results file\n",
        "BINARY_RESULTS_FILE_PATH = os.path.join(BINARY_RESULTS_SAVE_PATH, \"binary_model_evaluation_results.txt\")\n",
        "\n",
        "# Evaluating Models and Generating Reports\n",
        "with open(BINARY_RESULTS_FILE_PATH, \"w\") as f:\n",
        "    for model_name, model in trained_models.items():\n",
        "        f.write(f\"\\nEvaluating {model_name.replace('_', ' ').capitalize()} on the Binary Test Set:\\n{'-' * 40}\\n\")\n",
        "\n",
        "        # Predict on the test set\n",
        "        y_pred_binary = model.predict(X_test_binary)\n",
        "\n",
        "        # Calculate standard metrics\n",
        "        accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
        "        report = classification_report(y_test_binary, y_pred_binary, output_dict=True, zero_division=0)\n",
        "        confusion = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "\n",
        "        # Save confusion matrix heatmap\n",
        "        normalized_matrix = confusion / confusion.sum(axis=1, keepdims=True)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(normalized_matrix, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "                    xticklabels=[\"Normal\", \"Attack\"],\n",
        "                    yticklabels=[\"Normal\", \"Attack\"])\n",
        "        plt.title(f\"Confusion Matrix Heatmap: {model_name.replace('_', ' ').capitalize()}\")\n",
        "        plt.xlabel(\"Predicted Class\")\n",
        "        plt.ylabel(\"Actual Class\")\n",
        "        heatmap_path = os.path.join(BINARY_RESULTS_SAVE_PATH, f\"{model_name.replace('_', '-')}_Binary_Heatmap.png\")\n",
        "        plt.savefig(heatmap_path)\n",
        "        plt.close()\n",
        "        f.write(f\"Saved heatmap to {heatmap_path}\\n\")\n",
        "\n",
        "        # Extract precision, recall, and F1 scores\n",
        "        class_scores = {\n",
        "            class_label: {\n",
        "                \"Precision\": report[str(class_label)]['precision'],\n",
        "                \"Recall\": report[str(class_label)]['recall'],\n",
        "                \"F1 Score\": report[str(class_label)]['f1-score']\n",
        "            }\n",
        "            for class_label in [0, 1]  # Binary classes: 0 (Normal), 1 (Attack)\n",
        "        }\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        overall_precision = np.mean([class_scores[label][\"Precision\"] for label in class_scores])\n",
        "        overall_recall = np.mean([class_scores[label][\"Recall\"] for label in class_scores])\n",
        "        overall_f1_score = np.mean([class_scores[label][\"F1 Score\"] for label in class_scores])\n",
        "\n",
        "        # Calculate false positives/negatives\n",
        "        misclassified_as_normal = np.sum((y_pred_binary == 0) & (y_test_binary == 1))\n",
        "        false_alarms = np.sum((y_pred_binary == 1) & (y_test_binary == 0))\n",
        "\n",
        "        # Save overall metrics to file\n",
        "        f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
        "        f.write(f\"Overall Precision: {overall_precision:.4f}\\n\")\n",
        "        f.write(f\"Overall Recall: {overall_recall:.4f}\\n\")\n",
        "        f.write(f\"Overall F1 Score: {overall_f1_score:.4f}\\n\")\n",
        "        f.write(f\"Misclassified as Normal (False Negatives): {misclassified_as_normal}/{total_attacks}\\n\")\n",
        "        f.write(f\"False Alarms (False Positives): {false_alarms}/{total_normals}\\n\")\n",
        "\n",
        "        # Save class-wise metrics\n",
        "        f.write(\"\\nClass-Wise Metrics:\\n\")\n",
        "        for class_label in [0, 1]:  # Binary classes\n",
        "            f.write(f\"Class {class_label} ({['Normal', 'Attack'][class_label]}):\\n\")\n",
        "            f.write(f\"  Precision: {class_scores[class_label]['Precision']:.4f}\\n\")\n",
        "            f.write(f\"  Recall:    {class_scores[class_label]['Recall']:.4f}\\n\")\n",
        "            f.write(f\"  F1 Score:  {class_scores[class_label]['F1 Score']:.4f}\\n\")\n",
        "\n",
        "        # Save confusion matrix in file\n",
        "        f.write(\"\\nConfusion Matrix:\\n\")\n",
        "        f.write(np.array2string(confusion) + \"\\n\")\n",
        "\n",
        "print(f\"All evaluation results saved to {BINARY_RESULTS_FILE_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clrsH0hbZauS",
        "outputId": "69856b5f-78d5-4e56-9e1d-8c951b3acbce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All evaluation results saved to /content/drive/MyDrive/MachineLearning/new_imported_dataset/binary_thesis/Confusion_matrices/evaluation_results_binary.txt\n"
          ]
        }
      ]
    }
  ]
}